\contentsline {figure}{\numberline {1}{\ignorespaces Different behaviour the distribution for different initial parameters of the $\alpha $ vector}}{11}{figure.1}
\contentsline {figure}{\numberline {2}{\ignorespaces Realizations from a Dirichlet distribution using the stick breaking construction in $R^3$. Each color represents the weight of the respective component. Weights sum up to 1 making every realization a probability mass function. A single line can be mapped to a single dot in Fig. \ref {firstplot} }}{12}{figure.2}
\contentsline {figure}{\numberline {3}{\ignorespaces Polya's urn for $\alpha $=[2 1 1] }}{13}{figure.3}
\contentsline {figure}{\numberline {4}{\ignorespaces The CRP process}}{14}{figure.4}
\contentsline {figure}{\numberline {5}{\ignorespaces The stick breaking process. Every part of the stick represents the number of customers sitting at that specific table in the CRP process. It can be seen that the higher values of $\alpha $ lead to realizations that are closer to the base distribution. It is clear that realizations of a Dirichlet process are discrete distributions.}}{16}{figure.5}
\contentsline {figure}{\numberline {6}{\ignorespaces Mixture model}}{16}{figure.6}
\contentsline {figure}{\numberline {7}{\ignorespaces A Dirichlet process mixture model.}}{17}{figure.7}
\contentsline {figure}{\numberline {8}{\ignorespaces GPU as a function of CRP}}{18}{figure.8}
\contentsline {figure}{\numberline {9}{\ignorespaces General landmark update pipeline}}{19}{figure.9}
\contentsline {figure}{\numberline {10}{\ignorespaces Point cloud modification pipeline.}}{20}{figure.10}
\contentsline {figure}{\numberline {11}{\ignorespaces Exponential trend}}{20}{figure.11}
\contentsline {figure}{\numberline {12}{\ignorespaces Initial data along with the distributions infered }}{28}{figure.12}
\contentsline {figure}{\numberline {13}{\ignorespaces More complicated color distributions}}{29}{figure.13}
\contentsline {figure}{\numberline {14}{\ignorespaces The colour and position boundary is displayed in these pictures}}{31}{figure.14}
\contentsline {figure}{\numberline {15}{\ignorespaces SLAM session using the pipeline. The pipeline is used as the sensor model of an EKF-SLAM module. The readings of a kinect mounted on a turtlebot are downsampled and clustered. Current readings are either being matched to past readings giving old landmarks or being used to create new landmarks if no similar past environment sigantures exist. Landmarks are represented with yellow spheres. }}{32}{figure.15}
\contentsline {figure}{\numberline {16}{\ignorespaces Memory Requirements as a function of strength parameter $\alpha $.}}{34}{figure.16}
\contentsline {figure}{\numberline {17}{\ignorespaces Result of a session using RTAB-map module. The resulting map captures the structure of the room and the maps for the room shown in the picture average 84MB in size.}}{34}{figure.17}
\contentsline {figure}{\numberline {18}{\ignorespaces The behaviour of the dowsampling module with respect to the threshold of the operations.}}{37}{figure.18}
\contentsline {figure}{\numberline {19}{\ignorespaces Unsupervised entity extraction.}}{37}{figure.19}
\contentsline {figure}{\numberline {20}{\ignorespaces Cases where using very low/high values on the hyperparameter $\alpha $ lead to a pipeline that either groups the whole cloud being to a single landmark or to a pipeline that constantly creates new landmarks.}}{39}{figure.20}
\contentsline {figure}{\numberline {21}{\ignorespaces Memory requirements with respect to the number of landmarks in the environment. 10000 landmarks have memory needs of 2.6MB making the method very memory efficient.}}{40}{figure.21}
